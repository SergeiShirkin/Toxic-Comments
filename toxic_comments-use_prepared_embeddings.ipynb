{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout, SpatialDropout1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_name = 'input/train.csv'\n",
    "test_name = 'input/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      "id               159571 non-null object\n",
      "comment_text     159571 non-null object\n",
      "toxic            159571 non-null int64\n",
      "severe_toxic     159571 non-null int64\n",
      "obscene          159571 non-null int64\n",
      "threat           159571 non-null int64\n",
      "insult           159571 non-null int64\n",
      "identity_hate    159571 non-null int64\n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(test_name, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = list(train.columns[2:])\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = \"input/train.csv\"\n",
    "VOCAB_SIZE = 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = collections.Counter()\n",
    "#fin = open(INPUT_FILE, \"r\", encoding = 'utf8')\n",
    "maxlen = 0\n",
    "line_sizes = []\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    #clean a line\n",
    "    line = train['comment_text'].values[i].replace('\"', '').replace('\\n', '').replace('\\'', '')\n",
    "    #make a list of word in a line (with purpose to know the maximum length of the line)\n",
    "    words = [x.lower() for x in nltk.word_tokenize(line)]\n",
    "    #line sizes\n",
    "    line_sizes.append(len(words))\n",
    "    if len(words) > maxlen:\n",
    "        maxlen = len(words)\n",
    "    for word in words:\n",
    "        counter[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index = collections.defaultdict(int)\n",
    "for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n",
    "    #word[0] is the word itself and word[1] is its frequency in the file\n",
    "    #so for word2index dictionary we only need word[0]\n",
    "    word2index[word[0]] = wid + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302705"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word2index) + 1\n",
    "index2word = {v:k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4948"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_sizes_arr = np.array(line_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I decided to cut off the long sentences by 300 words\n",
    "maxlen = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, "
     ]
    }
   ],
   "source": [
    "xs, ys = np.zeros((train.shape[0], maxlen)), np.zeros((train.shape[0], 6))\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    #clean a line\n",
    "    line = train['comment_text'].values[i].replace('\"', '').replace('\\n', '').replace('\\'', '')\n",
    "        \n",
    "    words = [x.lower() for x in nltk.word_tokenize(line)][:maxlen]\n",
    "    wids = [word2index[word] for word in words]\n",
    "    wids_padded = wids + [0] * (maxlen - len(wids))\n",
    "    xs[i] = np.array(wids_padded)\n",
    "    \n",
    "    ys[i] = train.iloc[i, 2:].values\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print(i, end = ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 300)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #xs_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, "
     ]
    }
   ],
   "source": [
    "xs_sub = np.zeros((sub.shape[0], maxlen))\n",
    "\n",
    "for i in range(sub.shape[0]):\n",
    "    #clean a line\n",
    "    line_sub = sub['comment_text'].values[i].replace('\"', '').replace('\\n', '').replace('\\'', '')\n",
    "        \n",
    "    words_sub = [x.lower() for x in nltk.word_tokenize(line_sub)][:maxlen]\n",
    "    wids_sub = [word2index[word] for word in words_sub]\n",
    "    wids_padded_sub = wids_sub + [0] * (maxlen - len(wids_sub))\n",
    "    xs_sub[i] = np.array(wids_padded_sub)\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print(i, end = ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 300)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #AUC - for Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub = np.zeros((sub.shape[0], 6))\n",
    "y_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.contrib.metrics import streaming_auc\n",
    "import tensorflow as tf\n",
    "\n",
    "def roc_auc2(y_true, y_pred):\n",
    "    a = roc_auc_score(y_true, tf.Session().run(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD2VEC_MODEL = '../word_embeddings/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load word2vec model\n",
    "#gensim.models.KeyedVectors instead of gensim.models.Word2Vec (deprecated)\n",
    "import gensim\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(WORD2VEC_MODEL, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBED_SIZE = 300\n",
    "embedding_weights = np.zeros((vocab_size, EMBED_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word, index in word2index.items():\n",
    "    try:\n",
    "        embedding_weights[index, :] = word2vec[word]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ITERATION 0: toxic\n",
      "\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/5\n",
      "111699/111699 [==============================] - 184s 2ms/step - loss: 0.1410 - acc: 0.9506 - val_loss: 0.1044 - val_acc: 0.9613\n",
      "roc-auc: 0.9822 - roc-auc_val: 0.9754                                                                                                    \n",
      "Epoch 2/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0987 - acc: 0.9628 - val_loss: 0.1036 - val_acc: 0.9619\n",
      "roc-auc: 0.9888 - roc-auc_val: 0.9767                                                                                                    \n",
      "Epoch 3/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0855 - acc: 0.9671 - val_loss: 0.1036 - val_acc: 0.9622\n",
      "roc-auc: 0.9934 - roc-auc_val: 0.9757                                                                                                    \n",
      "Epoch 4/5\n",
      "111699/111699 [==============================] - 181s 2ms/step - loss: 0.0712 - acc: 0.9727 - val_loss: 0.1117 - val_acc: 0.9607\n",
      "roc-auc: 0.9966 - roc-auc_val: 0.973                                                                                                    \n",
      "Epoch 5/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0595 - acc: 0.9774 - val_loss: 0.1292 - val_acc: 0.9601\n",
      "roc-auc: 0.9986 - roc-auc_val: 0.9703                                                                                                    \n",
      "\n",
      "ITERATION 1: severe_toxic\n",
      "\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/5\n",
      "111699/111699 [==============================] - 183s 2ms/step - loss: 0.0424 - acc: 0.9880 - val_loss: 0.0266 - val_acc: 0.9905\n",
      "roc-auc: 0.991 - roc-auc_val: 0.986                                                                                                    \n",
      "Epoch 2/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0239 - acc: 0.9909 - val_loss: 0.0249 - val_acc: 0.9906\n",
      "roc-auc: 0.9951 - roc-auc_val: 0.987                                                                                                    \n",
      "Epoch 3/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0196 - acc: 0.9921 - val_loss: 0.0265 - val_acc: 0.9890\n",
      "roc-auc: 0.9972 - roc-auc_val: 0.9856                                                                                                    \n",
      "Epoch 4/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0160 - acc: 0.9934 - val_loss: 0.0282 - val_acc: 0.9891\n",
      "roc-auc: 0.9987 - roc-auc_val: 0.9814                                                                                                    \n",
      "Epoch 5/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0121 - acc: 0.9952 - val_loss: 0.0322 - val_acc: 0.9898\n",
      "roc-auc: 0.9995 - roc-auc_val: 0.9755                                                                                                    \n",
      "\n",
      "ITERATION 2: obscene\n",
      "\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/5\n",
      "111699/111699 [==============================] - 183s 2ms/step - loss: 0.0844 - acc: 0.9739 - val_loss: 0.0586 - val_acc: 0.9788\n",
      "roc-auc: 0.9891 - roc-auc_val: 0.9859                                                                                                    \n",
      "Epoch 2/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0541 - acc: 0.9814 - val_loss: 0.0565 - val_acc: 0.9797\n",
      "roc-auc: 0.9933 - roc-auc_val: 0.9869                                                                                                    \n",
      "Epoch 3/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0476 - acc: 0.9831 - val_loss: 0.0574 - val_acc: 0.9796\n",
      "roc-auc: 0.9961 - roc-auc_val: 0.986                                                                                                    \n",
      "Epoch 4/5\n",
      "111699/111699 [==============================] - 181s 2ms/step - loss: 0.0386 - acc: 0.9859 - val_loss: 0.0615 - val_acc: 0.9787\n",
      "roc-auc: 0.9982 - roc-auc_val: 0.9844                                                                                                    \n",
      "Epoch 5/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0311 - acc: 0.9886 - val_loss: 0.0676 - val_acc: 0.9788\n",
      "roc-auc: 0.9993 - roc-auc_val: 0.9811                                                                                                    \n",
      "\n",
      "ITERATION 3: threat\n",
      "\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/5\n",
      "111699/111699 [==============================] - 183s 2ms/step - loss: 0.0257 - acc: 0.9962 - val_loss: 0.0093 - val_acc: 0.9975\n",
      "roc-auc: 0.9924 - roc-auc_val: 0.9845                                                                                                    \n",
      "Epoch 2/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.0085 - val_acc: 0.9975\n",
      "roc-auc: 0.9985 - roc-auc_val: 0.9886                                                                                                    \n",
      "Epoch 3/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0086 - val_acc: 0.9974\n",
      "roc-auc: 0.9996 - roc-auc_val: 0.9885                                                                                                    \n",
      "Epoch 4/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0104 - val_acc: 0.9970\n",
      "roc-auc: 0.9999 - roc-auc_val: 0.9853                                                                                                    \n",
      "Epoch 5/5\n",
      "111699/111699 [==============================] - 181s 2ms/step - loss: 0.0030 - acc: 0.9989 - val_loss: 0.0106 - val_acc: 0.9973\n",
      "roc-auc: 1.0 - roc-auc_val: 0.9776                                                                                                    \n",
      "\n",
      "ITERATION 4: insult\n",
      "\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/5\n",
      "111699/111699 [==============================] - 183s 2ms/step - loss: 0.0916 - acc: 0.9684 - val_loss: 0.0710 - val_acc: 0.9729\n",
      "roc-auc: 0.9861 - roc-auc_val: 0.981                                                                                                    \n",
      "Epoch 2/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0659 - acc: 0.9743 - val_loss: 0.0703 - val_acc: 0.9728\n",
      "roc-auc: 0.9918 - roc-auc_val: 0.9823                                                                                                    \n",
      "Epoch 3/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0554 - acc: 0.9784 - val_loss: 0.0717 - val_acc: 0.9724\n",
      "roc-auc: 0.9949 - roc-auc_val: 0.9818                                                                                                    \n",
      "Epoch 4/5\n",
      "111699/111699 [==============================] - 181s 2ms/step - loss: 0.0461 - acc: 0.9824 - val_loss: 0.0787 - val_acc: 0.9710\n",
      "roc-auc: 0.9977 - roc-auc_val: 0.979                                                                                                    \n",
      "Epoch 5/5\n",
      "111699/111699 [==============================] - 181s 2ms/step - loss: 0.0372 - acc: 0.9859 - val_loss: 0.0892 - val_acc: 0.9699\n",
      "roc-auc: 0.9991 - roc-auc_val: 0.9717                                                                                                    \n",
      "\n",
      "ITERATION 5: identity_hate\n",
      "\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/5\n",
      "111699/111699 [==============================] - 183s 2ms/step - loss: 0.0470 - acc: 0.9870 - val_loss: 0.0267 - val_acc: 0.9923\n",
      "roc-auc: 0.9844 - roc-auc_val: 0.9729                                                                                                    \n",
      "Epoch 2/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0225 - acc: 0.9929 - val_loss: 0.0272 - val_acc: 0.9909\n",
      "roc-auc: 0.9933 - roc-auc_val: 0.9741                                                                                                    \n",
      "Epoch 3/5\n",
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0179 - acc: 0.9939 - val_loss: 0.0264 - val_acc: 0.9921\n",
      "roc-auc: 0.9972 - roc-auc_val: 0.9682                                                                                                    \n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111699/111699 [==============================] - 182s 2ms/step - loss: 0.0133 - acc: 0.9954 - val_loss: 0.0286 - val_acc: 0.9921\n",
      "roc-auc: 0.9987 - roc-auc_val: 0.9622                                                                                                    \n",
      "Epoch 5/5\n",
      "111699/111699 [==============================] - 181s 2ms/step - loss: 0.0102 - acc: 0.9964 - val_loss: 0.0321 - val_acc: 0.9914\n",
      "roc-auc: 0.9994 - roc-auc_val: 0.9543                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 5\n",
    "NUM_FILTERS = 1024\n",
    "NUM_WORDS = 4\n",
    "\n",
    "for i in range(6):\n",
    "    print('\\nITERATION {}: {}\\n'.format(i, target_names[i]))\n",
    "    Y1 = np_utils.to_categorical(ys[:, i])\n",
    "    #print('Y1.shape: {}'.format(Y1.shape))\n",
    "\n",
    "    #print('Y1[:, 1].mean(): {}'.format(Y1[:, 1].mean()))\n",
    "\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(xs, Y1, test_size=0.3, random_state=42)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, EMBED_SIZE, input_length=maxlen,\n",
    "                       weights = [embedding_weights]))\n",
    "    model.add(SpatialDropout1D(0.4))\n",
    "    model.add(Conv1D(filters=NUM_FILTERS, kernel_size=NUM_WORDS, activation=\"relu\"))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint('models/model_{}.h5'.format(i), \n",
    "                                   monitor = 'val_acc',\n",
    "                                   verbose=0, \n",
    "                                   save_best_only=True,\n",
    "                                   mode = 'max')\n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        validation_data=(Xtest, Ytest),\n",
    "                        callbacks=[checkpointer,\n",
    "                                   roc_callback(training_data=(Xtrain, Ytrain),\n",
    "                                                validation_data=(Xtest, Ytest))])\n",
    "\n",
    "    model = load_model('models/model_{}.h5'.format(i))\n",
    "    \n",
    "    y_sub[:, i] = model.predict(xs_sub)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99753177e-01, 1.60092175e-01, 9.95434701e-01, 6.82387650e-02,\n",
       "        9.60392654e-01, 1.65845290e-01],\n",
       "       [4.58791561e-04, 1.51148837e-04, 2.07091356e-03, 4.71603307e-05,\n",
       "        1.75901374e-03, 1.11201825e-03],\n",
       "       [4.62455899e-02, 1.37704052e-03, 1.65415835e-02, 1.34225465e-05,\n",
       "        7.23181153e-03, 1.39323471e-03],\n",
       "       ...,\n",
       "       [5.52542333e-04, 2.93768331e-04, 9.83823789e-04, 2.01073926e-04,\n",
       "        1.05217553e-03, 4.57630988e-04],\n",
       "       [1.68083597e-03, 3.04245827e-04, 3.34065314e-03, 5.48638753e-04,\n",
       "        4.57949936e-03, 2.83632129e-02],\n",
       "       [9.77569163e-01, 1.24748365e-03, 6.66202664e-01, 3.14978277e-03,\n",
       "        1.65339932e-01, 7.04401964e-03]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub1 = sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, item in enumerate(target_names):\n",
    "    sub1[item] = y_sub[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub1.drop('comment_text', axis = 1).to_csv('output/sub11.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>0.160092</td>\n",
       "      <td>0.995435</td>\n",
       "      <td>0.068239</td>\n",
       "      <td>0.960393</td>\n",
       "      <td>0.165845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>0.046246</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.016542</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>0.014026</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>Please do not add nonsense to Wikipedia. Such ...</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>0.494491</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.017229</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>0.002629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>\" \\n Only a fool can believe in such numbers. ...</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.014373</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.018738</td>\n",
       "      <td>0.000771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>== Double Redirects == \\n\\n When fixing double...</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "5  0001ea8717f6de06  Thank you for understanding. I think very high...   \n",
       "6  00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...   \n",
       "7  000247e83dcc1211                   :Dear god this site is horrible.   \n",
       "8  00025358d4737918  \" \\n Only a fool can believe in such numbers. ...   \n",
       "9  00026d1092fe71cc  == Double Redirects == \\n\\n When fixing double...   \n",
       "\n",
       "      toxic  severe_toxic   obscene    threat    insult  identity_hate  \n",
       "0  0.999753      0.160092  0.995435  0.068239  0.960393       0.165845  \n",
       "1  0.000459      0.000151  0.002071  0.000047  0.001759       0.001112  \n",
       "2  0.046246      0.001377  0.016542  0.000013  0.007232       0.001393  \n",
       "3  0.000190      0.000154  0.000687  0.000044  0.001032       0.000166  \n",
       "4  0.014026      0.001095  0.004249  0.000468  0.009468       0.001160  \n",
       "5  0.000788      0.000133  0.000469  0.000233  0.001087       0.000229  \n",
       "6  0.002254      0.000065  0.001079  0.000033  0.001222       0.000453  \n",
       "7  0.494491      0.000782  0.017229  0.000520  0.016560       0.002629  \n",
       "8  0.007183      0.000577  0.014373  0.001088  0.018738       0.000771  \n",
       "9  0.000122      0.000117  0.001747  0.000139  0.001440       0.000485  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
